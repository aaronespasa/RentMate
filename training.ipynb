{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('_id', axis=1, inplace=True)\n",
    "df.drop('Deposit', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Encoding & Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot Encoding has to be done after the train-validation-test split for several reasons:\n",
    "1. **Data Leakage Prevention**: If we do the one-hot encoding before the split, we will be using information from the validation and test sets to encode the categorical variables. This is a problem because we are using information from the validation and test sets to train our model, which is not allowed.\n",
    "2. **Avoiding the Curse of Dimensionality**: If we do the one-hot encoding before the split, we will be increasing the number of columns in the dataset. This is a problem because we will be increasing the number of dimensions of the dataset, which will make the model more complex and prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Label Encoding of 'Floor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bajo exterior',\n",
       " 'no aplica',\n",
       " 'bajo interior',\n",
       " 'semi-sótano interior',\n",
       " 'semi-sótano exterior',\n",
       " ' exterior',\n",
       " 'entreplanta interior',\n",
       " 'bajo',\n",
       " 'entreplanta exterior',\n",
       " 'sótano exterior',\n",
       " ' interior',\n",
       " 'sótano interior']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique values of the column 'Floor' of df\n",
    "floor_unique = df['Floor'].unique()\n",
    "# remove the samples that have 'planta in floor_unique (but avoid entreplanta)\n",
    "floor_values_without_planta = [x for x in floor_unique if 'planta ' not in x or 'entreplanta' in x]\n",
    "floor_values_without_planta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'bajo exterior', 'bajo interior', 'bajo': 0\n",
    "\n",
    "* 'semi-sótano interior', 'semi-sótano exterior': -1\n",
    "\n",
    "* 'sótano interior', 'sótano exterior': -2\n",
    "\n",
    "And the rest of the values are very differentiated to make them more \"neutral\":\n",
    "\n",
    "* 'entreplanta interior', 'entreplanta exterior': -100\n",
    "\n",
    "* 'exterior', 'interior': -999\n",
    "\n",
    "* 'no aplica': 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Floor'] = df['Floor'].apply(extract_floor_number).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-999, -100, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 30, 53, 60, 999]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df['Floor'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8280"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. One-Hot Encoding of 'Type'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the column 'Type' using one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
